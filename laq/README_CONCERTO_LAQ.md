# Concerto-LAQ: 2D+3D Aware Latent Action Quantization

This project integrates **Concerto** (joint 2D-3D self-supervised learning) with **LAQ** (Latent Action Quantization) to predict actions in a latent space with 3D awareness.

---

## ğŸ—ï¸ Complete Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                             Concerto-LAQ Pipeline                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                  â”‚
â”‚    Frame t [224Ã—224Ã—3]              Frame t+1 [224Ã—224Ã—3]                       â”‚
â”‚          â”‚                                â”‚                                      â”‚
â”‚          â–¼                                â–¼                                      â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚    â”‚   VGGT   â”‚                     â”‚   VGGT   â”‚   Single-frame 3D estimation   â”‚
â”‚    â”‚    1B    â”‚                     â”‚    1B    â”‚   - Depth map                  â”‚
â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   - Camera intrinsics          â”‚
â”‚         â”‚                                â”‚         - Point cloud                 â”‚
â”‚         â–¼                                â–¼                                       â”‚
â”‚    Point Cloud                     Point Cloud                                  â”‚
â”‚    [50K points]                    [50K points]                                 â”‚
â”‚         â”‚                                â”‚                                       â”‚
â”‚         â–¼                                â–¼                                       â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚    â”‚ Subsampleâ”‚                     â”‚ Subsampleâ”‚   Random sampling              â”‚
â”‚    â”‚  â†’ 8K    â”‚                     â”‚  â†’ 8K    â”‚   (å¯åˆ‡æ›ç‚º FPS)               â”‚
â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚         â”‚                                â”‚                                       â”‚
â”‚         â–¼                                â–¼                                       â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚    â”‚ Concerto â”‚                     â”‚ Concerto â”‚   PTv3 3D Transformer          â”‚
â”‚    â”‚  (PTv3)  â”‚                     â”‚  (PTv3)  â”‚   108M params (base)           â”‚
â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚         â”‚                                â”‚                                       â”‚
â”‚         â–¼                                â–¼                                       â”‚
â”‚    [8K, 512]                        [8K, 512]     Sparse point features         â”‚
â”‚         â”‚                                â”‚                                       â”‚
â”‚         â–¼                                â–¼                                       â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚    â”‚ Sparse-to-   â”‚                 â”‚ Sparse-to-   â”‚   Learnable projection     â”‚
â”‚    â”‚ Dense (S2D)  â”‚                 â”‚ Dense (S2D)  â”‚   Cross-attention          â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚           â”‚                                â”‚                                     â”‚
â”‚           â–¼                                â–¼                                     â”‚
â”‚    [14Ã—14Ã—512]                      [14Ã—14Ã—512]     Dense 2D features           â”‚
â”‚           â”‚                                â”‚                                     â”‚
â”‚           â–¼                                â–¼                                     â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚    â”‚  Feature     â”‚                 â”‚  Feature     â”‚   512 â†’ model_dim          â”‚
â”‚    â”‚  Projection  â”‚                 â”‚  Projection  â”‚                            â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚           â”‚                                â”‚                                     â”‚
â”‚           â–¼                                â–¼                                     â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚    â”‚   Spatial    â”‚                 â”‚   Spatial    â”‚   Transformer encoder      â”‚
â”‚    â”‚   Encoder    â”‚                 â”‚   Encoder    â”‚   with 2D pos encoding     â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚           â”‚                                â”‚                                     â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                        â–¼                                                         â”‚
â”‚                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                 â”‚
â”‚                â”‚   Temporal   â”‚   Compute difference between frame features    â”‚
â”‚                â”‚   Encoder    â”‚                                                 â”‚
â”‚                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                                 â”‚
â”‚                       â”‚                                                          â”‚
â”‚                       â–¼                                                          â”‚
â”‚                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                 â”‚
â”‚                â”‚     NSVQ     â”‚   Normalize-Scale Vector Quantization          â”‚
â”‚                â”‚  Quantizer   â”‚   Codebook: 256 codes                          â”‚
â”‚                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                                 â”‚
â”‚                       â”‚                                                          â”‚
â”‚                       â–¼                                                          â”‚
â”‚               Action Codes [4]   4 discrete tokens per frame pair              â”‚
â”‚                                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” Sparse-to-Dense Projection (Cross-Attention)

é€™æ˜¯å°‡ç¨€ç–é»é›²ç‰¹å¾µ [N, 512] è½‰æ›ç‚ºå¯†é›† 2D feature map [14Ã—14, 512] çš„æ ¸å¿ƒæ¨¡å¡Šã€‚

### åŸç†

ä½¿ç”¨é¡ä¼¼ DETR çš„ **Object Queries** æ¦‚å¿µï¼Œä½†ç”¨æ–¼**ç©ºé–“ç‰¹å¾µé‡å»º**ï¼š

1. **Spatial Queries**: å¯å­¸ç¿’çš„ 14Ã—14=196 å€‹ä½ç½®æŸ¥è©¢å‘é‡
2. **Cross-Attention**: æ¯å€‹æŸ¥è©¢å‘é‡ã€Œè©¢å•ã€æ‰€æœ‰é»é›²ç‰¹å¾µï¼Œå­¸ç¿’æœ€ç›¸é—œçš„ä¿¡æ¯
3. **è¼¸å‡º**: æ¯å€‹ç©ºé–“ä½ç½®å¾—åˆ°ä¸€å€‹èšåˆå¾Œçš„ç‰¹å¾µå‘é‡

### è©³ç´°æµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Cross-Attention è©³è§£                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   Point Features (Keys & Values)        Spatial Queries                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   â”‚ pâ‚ pâ‚‚ pâ‚ƒ ... pâ‚ˆâ‚â‚‰â‚‚     â”‚           â”‚ qâ‚ qâ‚‚ ... qâ‚â‚‰â‚†      â”‚           â”‚
â”‚   â”‚ [8192, 512]             â”‚           â”‚ [196, 512]          â”‚           â”‚
â”‚   â”‚ å¾ Concerto è¼¸å‡º        â”‚           â”‚ å¯å­¸ç¿’çš„ä½ç½®å‘é‡    â”‚           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚               â”‚                                    â”‚                        â”‚
â”‚               â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚                        â”‚
â”‚               â””â”€â”€â”€â–ºâ”‚      Cross-Attention        â”‚â—„â”˜                        â”‚
â”‚                    â”‚                             â”‚                          â”‚
â”‚                    â”‚  Attention(Q, K, V)         â”‚                          â”‚
â”‚                    â”‚  Q = Spatial Queries        â”‚                          â”‚
â”‚                    â”‚  K = Point Features         â”‚                          â”‚
â”‚                    â”‚  V = Point Features         â”‚                          â”‚
â”‚                    â”‚                             â”‚                          â”‚
â”‚                    â”‚  attn = softmax(QÂ·K^T/âˆšd)   â”‚                          â”‚
â”‚                    â”‚  output = attn Â· V          â”‚                          â”‚
â”‚                    â”‚                             â”‚                          â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                                   â”‚                                          â”‚
â”‚                                   â–¼                                          â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                    â”‚     FFN (Feed-Forward)      â”‚                          â”‚
â”‚                    â”‚     512 â†’ 2048 â†’ 512        â”‚                          â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                                   â”‚                                          â”‚
â”‚                                   â–¼                                          â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                    â”‚  Reshape to 2D Grid         â”‚                          â”‚
â”‚                    â”‚  [196, 512] â†’ [14, 14, 512] â”‚                          â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ•¸å­¸å…¬å¼

```
# Cross-Attention
Q = W_q @ spatial_queries           # [196, 512]
K = W_k @ point_features            # [8192, 512]
V = W_v @ point_features            # [8192, 512]

attention_weights = softmax(Q @ K^T / sqrt(512))    # [196, 8192]
output = attention_weights @ V                       # [196, 512]

# æ¯å€‹ spatial query å¾æ‰€æœ‰ 8192 å€‹é»ä¸­å­¸ç¿’è¦é—œæ³¨å“ªäº›
# æ¬Šé‡åˆ†å¸ƒæ±ºå®šäº†å¦‚ä½•èšåˆä¸åŒä½ç½®çš„é»ç‰¹å¾µ
```

### ç‚ºä»€éº¼é€™æ¨£è¨­è¨ˆï¼Ÿ

| å•é¡Œ | è§£æ±ºæ–¹æ¡ˆ |
|------|----------|
| é»æ•¸ä¸å›ºå®š (subsampled) | Attention å°ä»»æ„é•·åº¦ K,V éƒ½é©ç”¨ |
| éœ€è¦å›ºå®šè¼¸å‡ºå°ºå¯¸ | Query æ•¸é‡å›ºå®š = 14Ã—14 |
| ä¿ç•™ç©ºé–“é—œä¿‚ | å¯å­¸ç¿’çš„ positional encoding |
| å…¨å±€ä¿¡æ¯æ•´åˆ | æ¯å€‹ query çœ‹åˆ°æ‰€æœ‰é» |

---

## ğŸ“¦ æ¨¡å¡Šè©³è§£

### 1. VGGTEncoder

```python
è¼¸å…¥: RGB image [B, 3, 224, 224]
è¼¸å‡º: {
    'depth_map': [B, 224, 224],        # æ·±åº¦åœ–
    'intrinsic': [B, 3, 3],            # ç›¸æ©Ÿå…§åƒ
    'extrinsic': [B, 4, 4],            # ç›¸æ©Ÿå¤–åƒ
    'point_map': [B, 224, 224, 3],     # 3D é»åº§æ¨™
}
```

### 2. ConcertoEncoder (PTv3)

```python
è¼¸å…¥: point_dict = {
    'coord': [N, 3],       # é»åº§æ¨™ (å·²æ­£è¦åŒ–åˆ° [-1, 1])
    'color': [N, 3],       # RGB é¡è‰²
    'normal': [N, 3],      # æ³•å‘é‡ (ç›®å‰ç”¨ zeros)
    'feat': [N, 9],        # coord + color + normal
    'grid_coord': [N, 3],  # é«”ç´ æ ¼åº§æ¨™
    'offset': [1],         # batch offset
}
è¼¸å‡º: {'feat': [N', 512]}  # N' æ˜¯ Concerto å…§éƒ¨è™•ç†å¾Œçš„é»æ•¸
```

### 3. SparseToDenseProjection

```python
è¼¸å…¥: point_features [N, 512]
è¼¸å‡º: dense_features [14, 14, 512]

æ¶æ§‹:
- spatial_queries: Parameter([1, 196, 512])
- query_pos: Learnable 2D positional encoding
- layers: 2 Ã— {CrossAttention, LayerNorm, FFN, LayerNorm}
- output_norm: LayerNorm

åƒæ•¸é‡: ~4.2M
```

### 4. ConcertoLAQ

```python
è¼¸å…¥: video [B, 3, 2, 224, 224]  # å…©å¹€
è¼¸å‡º: (loss, num_unique_codes)

å­æ¨¡å¡Š:
- feature_proj: 512 â†’ model_dim (512)
- spatial_encoder: Transformer Ã— 4 layers
- action_encoder: NSVQ Quantizer (256 codes, 4 tokens)
```

---

## ğŸ“Š åƒæ•¸çµ±è¨ˆ

| æ¨¡å¡Š | åƒæ•¸é‡ | å¯è¨“ç·´ |
|------|--------|--------|
| VGGT | ~1.3B | âŒ å‡çµ |
| Concerto (PTv3) | ~108M | âŒ å‡çµ |
| SparseToDense | ~4.2M | âœ… |
| Feature Projection | ~0.5M | âœ… |
| Spatial Encoder | ~25M | âœ… |
| NSVQ Quantizer | ~12M | âœ… |
| **Total Trainable** | **~42M** | |

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### å®‰è£

```bash
# VGGT
git clone https://github.com/facebookresearch/vggt.git
export PYTHONPATH=/path/to/vggt:$PYTHONPATH

# Concerto
git clone https://github.com/Pointcept/Concerto.git
pip install -e Concerto/

# Dependencies
pip install spconv-cu121 torch-scatter -f https://data.pyg.org/whl/torch-2.2.0+cu121.html
```

### è¨“ç·´

```bash
python laq/train_concerto_laq.py \
    --data_dir /path/to/something-something-v2 \
    --batch_size 2 \
    --num_steps 100000 \
    --lr 1e-4
```

---

## ğŸ“š åƒè€ƒ

- [VGGT](https://github.com/facebookresearch/vggt): Visual Geometry Grounded Transformer
- [Concerto](https://github.com/Pointcept/Concerto): Joint 2D-3D Self-Supervised Learning
- [PTv3](https://github.com/Pointcept/PointTransformerV3): Point Transformer V3
- [DETR](https://github.com/facebookresearch/detr): Object queries inspiration
